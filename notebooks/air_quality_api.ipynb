{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa6b8e7",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381fdaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from db_connection import start_engine\n",
    "from datetime import date\n",
    "\n",
    "engine = start_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b826de",
   "metadata": {},
   "source": [
    "### Function to fetch air pollution data for a given year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e428921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def air_pollution(year): \n",
    "    today = date.today()\n",
    "    if year == today.year:\n",
    "        end_date = today.strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        end_date = f\"{year}-12-31\"\n",
    "    params = {\n",
    "        \"latitude\": LAT,\n",
    "        \"longitude\": LON,\n",
    "        \"hourly\": \"pm10,pm2_5,nitrogen_dioxide,ozone,carbon_monoxide,sulphur_dioxide\",\n",
    "        \"start_date\": f\"{year}-01-01\",\n",
    "        \"end_date\": end_date,\n",
    "    }\n",
    "\n",
    "    data = requests.get(API_URL, params=params).json()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": data[\"hourly\"][\"time\"],\n",
    "        \"pm10\": data[\"hourly\"][\"pm10\"],\n",
    "        \"pm2_5\": data[\"hourly\"][\"pm2_5\"],\n",
    "        \"no2\": data[\"hourly\"][\"nitrogen_dioxide\"],\n",
    "        \"o3\": data[\"hourly\"][\"ozone\"],\n",
    "        \"co\": data[\"hourly\"][\"carbon_monoxide\"],\n",
    "        \"so2\": data[\"hourly\"][\"sulphur_dioxide\"],\n",
    "    })\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f571a",
   "metadata": {},
   "source": [
    "### Launching a code to take data from API and push to database Hamburg 2015-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d6c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/7rpxmwzd0q99rfstfcs03h400000gn/T/ipykernel_26252/1019232981.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_years_data = pd.concat(years_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "LAT = 53.5753\n",
    "LON = 10.0153 # Hamburg center coordinates\n",
    "years = range(2015,2026)   \n",
    "API_URL = \"https://air-quality-api.open-meteo.com/v1/air-quality\"\n",
    "\n",
    "years_data = [] # list to hold data for all years\n",
    "\n",
    "for n in years:\n",
    "    print(n)\n",
    "    new_data = air_pollution(n, f\"air_quality_{n}\")\n",
    "    years_data.append(new_data) # append yearly data to the list\n",
    "all_years_data = pd.concat(years_data, ignore_index=True) # concatenate all yearly data into a single DataFrame\n",
    "all_years_data.to_sql(name=\"air_quality_hamburg_2015_2025\", con=engine,\n",
    "                       if_exists=\"replace\", index=False) # push to SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf4213",
   "metadata": {},
   "source": [
    "### Fetch air pollution data for a specific year and district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def air_pollution_by_bezirk(year, bezirk, lat, lon): \n",
    "    today = date.today()\n",
    "\n",
    "    if year == today.year:\n",
    "        end_date = today.strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        end_date = f\"{year}-12-31\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"hourly\": \"pm10,pm2_5,nitrogen_dioxide,ozone,carbon_monoxide,sulphur_dioxide\",\n",
    "        \"start_date\": f\"{year}-01-01\",\n",
    "        \"end_date\": end_date,\n",
    "    }\n",
    "\n",
    "    raw = requests.get(API_URL, params=params).json()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": raw[\"hourly\"][\"time\"],\n",
    "        \"pm10\": raw[\"hourly\"][\"pm10\"],\n",
    "        \"pm2_5\": raw[\"hourly\"][\"pm2_5\"],\n",
    "        \"no2\": raw[\"hourly\"][\"nitrogen_dioxide\"],\n",
    "        \"o3\": raw[\"hourly\"][\"ozone\"],\n",
    "        \"co\": raw[\"hourly\"][\"carbon_monoxide\"],\n",
    "        \"so2\": raw[\"hourly\"][\"sulphur_dioxide\"],\n",
    "    })\n",
    "\n",
    "    df[\"year\"] = year\n",
    "    df[\"bezirk\"] = bezirk\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7180e6c",
   "metadata": {},
   "source": [
    "### Fetching the data and push it to database of Hamburg's districts air quality 2023-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e131ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Hamburg-Mitte\n",
      "Downloading Altona\n",
      "Downloading Eimsbüttel\n",
      "Downloading Hamburg-Nord\n",
      "Downloading Wandsbek\n",
      "Downloading Bergedorf\n",
      "Downloading Harburg\n"
     ]
    }
   ],
   "source": [
    "stations = {\n",
    "    \"Hamburg-Mitte\": (53.5450, 10.0150),\n",
    "    \"Altona\": (53.5560, 9.8810),\n",
    "    \"Eimsbüttel\": (53.5890, 9.9560),\n",
    "    \"Hamburg-Nord\": (53.6050, 10.0250),\n",
    "    \"Wandsbek\": (53.6050, 10.1200),\n",
    "    \"Bergedorf\": (53.4860, 10.2160),\n",
    "    \"Harburg\": (53.4600, 9.9830)\n",
    "} # Approximate coordinates of air quality stations in each Bezirk\n",
    "\n",
    "years = range(2023, 2026)\n",
    "all_data = []\n",
    "\n",
    "for bezirk, (lat, lon) in stations.items(): # Iterate over each Bezirk and its coordinates\n",
    "    print(f\"Downloading {bezirk}\")\n",
    "\n",
    "    for year in years:\n",
    "        df = air_pollution_by_bezirk(year, bezirk, lat, lon)\n",
    "        all_data.append(df) # Collect dataframes in a list\n",
    "\n",
    "final_df = pd.concat(all_data, ignore_index=True) # Concatenate all dataframes into one\n",
    "final_df.to_sql(name = \"air_quality_bezirk_2023_2025\", con= engine, # Push to DB\n",
    "                       if_exists= \"replace\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
